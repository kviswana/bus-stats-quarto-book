---
title: "How Much Variation Does a Model Explain?"
author: "Viswa Viswanathan"
fontsize: 12pt
output:
  pdf_document: 
     latex_engine: xelatex
  html_document: default
classoption: fleqn
header-includes:
  - \usepackage{titling}
  - \pretitle{\begin{flushleft}\LARGE}
  - \posttitle{\end{flushleft}}
  - \preauthor{\begin{flushleft}\large}
  - \postauthor{\end{flushleft}}
  - \predate{\begin{flushleft}\large}
  - \postdate{\end{flushleft}}

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(LSTbook)
```
## Introduction

This document helps you with the following questions:

- How do I build a model?
- How do I reconstruct the model function from the R model output (coefficients)?
- How do I compute the *total variance*, *model variance* and *residual variance*?
- How do I compute what proportion of the variability in the response variable the model *explains*, that is, the model's $R^2$?

## Variation in the Response Variable

We have used the *mpg* dataset for many examples and you should now be familiar with it. If we examine the contents of the column *hwy* which contains the highway miles per gallon of the cars, we see that there is variability -- not all cars have the same highway fuel efficiency.

Initially we might wonder why is there variability in *hwy*? What *explains* this variability? 

In the dataset, we see many other variables -- like *displ* (displacement of the engine), *fl* (fuel type used), *drv* (type of drive), among others. 

Clearly, the highway fuel efficiency of a car is related to some of these other variables. For example, we would expect that *displ* has something to do with *hwy* because an engine with a bigger *displ* or cylinder volume, will burn more fuel in each cycle.

Therefore, we can say that the dataset has cars with different values of *displ* and hence it is no surprise that the *hwy* values also vary -- because *hwy* is related to *displ* (and to other variables as well, but we are not considering them right now). Thus, we can say that *displ* **explains** *hwy*. 

## Building the model and getting the model function

We might want to build a model to **explain** *hwy* in terms of *displ*. That is, we might want to get an equation  that allows us to plug in the value of *displ* and determine a good value for *hwy* for a car with that value of *displ*. 

We use the *model_train* function to build the model.

``` {r}
mpg |> 
  model_train(hwy ~ displ)
```

The above code builds the model, but its output does not show us any useful information from which to get the model function. We therefore also use the *conf_interval* function as we see below.


``` {r}
mpg |> 
  model_train(hwy ~ displ) |> 
  conf_interval()
```

When trying to reconstruct the model function from the model coefficients, we only look at the values in the middle column -- the column named **.coef**.

From the above, the model function is:

$$
\widehat{hwy} = 35.7 - 3.53\, displ
$$
The small "hat" on top of *hwy* simply tells us that this is the *estimated* value for *hwy* based on the model and is not the actual value.

In the above example, our model has only a numerical explanatory variable *displ*. If a model has a categorical explanatory variable, the process of building the model function differs slightly. Let us build a model to explain *hwy* based on both *displ* and *drv*.

``` {r}
mpg |> 
  model_train(hwy ~ displ + drv) |> 
  conf_interval()
```
We still see the intercept and a coefficient for *displ*. But we also see some coefficients for *drv*. Since *drv* is categorical, we see coefficients for its possible values -- like "r" and "f". However, the coefficient is missing for the *drv* value "4". 

When we have a categorical explanatory variable, the coefficient listing always leaves out one of the values and includes it along with the intercept. In this case that it lect out the *drv* type "4". The coefficients for the other *drv* values are given relative to that for "4".

In this case the model function is:

$$
\widehat{\text{hwy}}
= 30.8
 - 2.91\,\text{displ}
 + 
\begin{cases}
0,      & \text{if } drv = "4" \\[6pt]
4.79,   & \text{if } drv = "f" \\[6pt]
5.26,   & \text{if } drv = "r"
\end{cases}
$$

Note that we treated the numerical variable *displ* just like before, but treated the categorical variable *drv* differently.\

## What do we mean by "model explains variability"

Let us start simple. Suppose we have data for many people (their height, weight, age, etc.) and see that their weights vary. Initially we many wonder why. However, we know that weight is related to other variables like height and age. In the dataset we see that we have people with different heights and different ages. So, we then say "Oh, that explains why I am seeing different weights. Since the people in our dataset have different heights and different ages, it is not a surprise that their weights vary as well". In statistical terms we say that the variables height and age *explain* weight. If we built a model that shows their connection more precisely as a mathematical equation, we can say that the model explains the variability in weight. As you can see, the idea of one variable or a model explaining variation of the response variable is pretty straightforward.

Getting back to the initial example, we see that *hwy* values show variability. Say we build a model with *hwy* as the response variable and some other variables as explanatory variables. If *hwy* is in fact related to these other variables, the model function tells us exactly how *hwy* is related to some other variables like *displ* and *drv* and since those variables exhibit variability, we should expect variability in the response variable *hwy* too. So the model explains variability in *hwy*, the response variable.



Our model tells us that we should expect variability in *hwy*. However, it might not explain all of the variability that actually exists. It accounts for some of the variability, but not all of it. A good model will account for a high proportion of the variability. This is why we try to compute how much variability a model explains -- or how good it is.

## The three variances of interest

It is one thing to say that a model explains variability in the response variable. However, we want to be more precise. Exactly how much variability in the response variable is because of its relationships with the explanatory variables? How much variability is the model unable to account for? We find these by computing three variances.

After building a model, we have, or can compute, the following three things for each row: 

- the actual value of the response variable (*hwy* in the above example)
- the model value for each row -- compute by plugging in the explanatory variable values for each row into the model function.
- the residual for each row -- difference between the prior two numbers.

Then we can compute the following three variances:

- *total variance* which is the variability of the **response variable** -- the variability we are trying to explain.

- *variance of the computed **model values*** for the rows in the dataset. This is the amount of variability that the model expects or explains.

- *variance of the **residuals*** or the variability that the model does not explain or expect.

**You will generally find that the model variance and the residual variance that you compute as above should add up to the total variance -- unless there are missing values of some or all of the variables involved in the model.**

We can use the following code to add the model values and the residuals to our data for the first model we built. I used "select" to show only the columns of interest.

```{r}
mpg |> 
  mutate (modval = model_values(hwy ~ displ),
          resid = hwy - modval) |> 
  select(hwy, modval, resid)
```

We can the extend the code to compute the three variances. We first look at the complete code and then explain it line by line.

```{r}
mpg |> 
  mutate (modval = model_values(hwy ~ displ),
          resid = hwy - modval) |> 
  summarize(tot_var = var(hwy),
            mod_var = var(modval),
            resid_var = var(resid))
```

From the output, we see that the total variability is 35.46 and the model accounts for or explains 20.8 of it. This model explains 20.8/35.46 or 58.7% of the variability.

Let us break down the code step by step to ensure that we understand each piece. 

```{r, eval=FALSE}
# Use the mpg dataset and pipe it to a function 
mpg |>  
 ... |> 
 ...
```
The first line (as shown above) just specifies the dataset we are using and prepares to pipe it to a function.

```{r, eval=FALSE}
mpg |> 
  # Use mutate to add columns for the model value and 
  # residual for each row -- residual is the difference 
  # between the model value and the actual value of hwy 
  # for each row. The model_values function computes the 
  # model value for each row. pipe the output of this 
  # line to the next function
 mutate (modval = model_values(hwy ~ displ),
          resid = hwy - modval) |>
  
 ... |> 
 ...
```

The above code uses the *model_values* function to compute the model value *modval* for each row. We then compute the residual *resid* as the difference between the actual value of *hwy* and the model value *modval*.

```{r, eval=FALSE}
mpg |> 
  mutate (modval = model_values(hwy ~ displ),
          resid = hwy - modval) |> 
  # Now compute the total variance, model values variance
  # and the residual variance using the summarize function
  summarize(tot_var = var(hwy),
            mod_var = var(modval),
            resid_var = var(resid))
```


We can increase the proportion of variability in *hwy* that the model explains, or the *explanatory power of the model* by adding more explanatory variables. Fortunately, we only need to change the tilde expression from our earlier code. Here we show the code to add *drv* as another explanatory variable.

```{r}
mpg |> 
  mutate (modval = model_values(hwy ~ displ + drv),
          resid = hwy - modval) |> 
  summarize(tot_var = var(hwy),
            mod_var = var(modval),
            resid_var = var(resid))
```

Now the model explains 26.1 out of 35.46 or 73.6% of the total variance.

A simpler way is to use the R2 function:

```{r}
mpg |> 
  model_train(hwy ~ displ + drv) |> 
  R2()
```
The R-Squared column shows the result. We can always use the R2 function, but I showed the longer way to help you understand what is going on.

Using the *R2* function avoids the issue with missing values of model variables.
